
nginx常用命令
    启动nginx  ./sbin/nginx
    停止nginx ./sbin/nginx -s stop    ./sbin/nginx -s quit

    重载配置  ./sbin/nginx -s reload(平滑重启)  service nginx reload 
    重载指定配置文件 ./sbin/nginx -c /usr/local/nginx/conf/nginx.conf

    查看nginx版本 ./sbin/nginx -v
    检查配置文件是否正确 ./sbin/nginx -t
    显示帮助信息 ./sbin/nginx -h


nginx功能
    反向代理服务器
    实现负载均衡
    虚拟主机

    1、多进程机制

    服务器每当收到一个客户端时，就有 服务器主进程 （ master process ）生成一个 子进程（ worker process ）出来和客户端建立连接进行交互，直到连接断开，该子进程就结束了。

    使用进程的好处是各个进程之间相互独立，不需要加锁，减少了使用锁对性能造成影响，同时降低编程的复杂度，降低开发成本。其次，采用独立的进程，可以让进程互相之间不会影响 ，如果一个进程发生异常退出时，其它进程正常工作， master 进程则很快启动新的 worker 进程，确保服务不会中断，从而将风险降到最低。

    缺点是操作系统生成一个子进程需要进行 内存复制等操作，在资源和时间上会产生一定的开销。当有大量请求时，会导致系统性能下降 。

    2、异步非阻塞机制

    每个工作进程 使用 异步非阻塞方式 ，可以处理 多个客户端请求 。

    当某个 工作进程 接收到客户端的请求以后，调用 IO 进行处理，如果不能立即得到结果，就去 处理其他请求 （即为 非阻塞 ）；而 客户端 在此期间也 无需等待响应 ，可以去处理其他事情（即为 异步 ）。

    当 IO 返回时，就会通知此 工作进程 ；该进程得到通知，暂时 挂起 当前处理的事务去 响应客户端请求 。



Nginx服务器上的Master和Worker进程
    Master进程：读取及评估配置和维持
    Worker进程：处理请求

    Nginx服务器上的Master和Worker进程

    主程序 Master process 启动后，通过一个 for 循环来 接收 和 处理外部信号 ；
    主进程通过 fork() 函数产生 worker 子进程 ，每个子进程执行一个 for循环来实现Nginx服务器对事件的接收和处理

    一般推荐 worker 进程数与CPU内核数一致，这样一来不存在大量的子进程生成和管理任务，避免了进程之间竞争CPU 资源和进程切换的开销。而且 Nginx 为了更好的利用 多核特性 ，提供了 CPU 亲缘性的绑定选项，我们可以将某一个进程绑定在某一个核上，这样就不会因为进程的切换带来 Cache 的失效。

    对于每个请求，有且只有一个工作进程 对其处理。首先，每个 worker 进程都是从 master进程 fork 过来。在 master 进程里面，先建立好需要 listen 的 socket（listenfd） 之后，然后再 fork 出多个 worker 进程。
    所有 worker 进程的 listenfd 会在新连接到来时变得可读 ，为保证只有一个进程处理该连接，所有 worker 进程在注册 listenfd 读事件前抢占 accept_mutex ，抢到互斥锁的那个进程注册 listenfd 读事件 ，在读事件里调用 accept 接受该连接。
    当一个 worker 进程在 accept 这个连接之后，就开始读取请求、解析请求、处理请求，产生数据后，再返回给客户端 ，最后才断开连接。这样一个完整的请求就是这样的了。我们可以看到，一个请求，完全由 worker 进程来处理，而且只在一个 worker 进程中处理。




nginx的常用算法实现

    round-robin
        round-robin的意思是循环轮询, Nginx最简单的负载均衡配置
    ```
    http {
        upstream app1 {
            server 10.10.10.1;
            server 10.10.10.2;
        }

        server {
            listen 80;
            location / {
                proxy_pass http://app1;
            }
    }
    ```

    upstream app1用来指定一个服务器组，该组的名字是app1，包含两台服务器。
    在指定服务器组里面包含的服务器时以形式"server ip/domain:port"的形式指定，其中80端口可以忽略。然后在接收到请求时通过“proxy_pass http://app1”把对应的请求转发到组app1上。Nginx默认的负载均衡算法就是循环轮询，如上配置我们采用的就是循环轮询，其会把接收到的请求循环的分发给其包含的（当前可用的）服务器。使用如上配置时，Nginx会把第1个请求给10.10.10.1，把第2个请求给10.10.10.2，第3个请求给10.10.10.1，以此类推。


    least-connected
        least-connected算法的中文翻译是最少连接，即每次都找连接数最少的服务器来转发请求。
        例如Nginx负载中有两台服务器，A和B，当Nginx接收到一个请求时，A正在处理的请求数是10，B正在处理的请求数是20，则Nginx会把当前请求交给A来处理。
        要启用最少连接负载算法只需要在定义服务器组时加上“least_conn”
    ```
    upstream app1 {
        least_conn;
        server 10.10.10.1;
        server 10.10.10.2;
    }
    ```


    ip-hash
        ip-hash算法会根据请求的客户端IP地址来决定当前请求应该交给谁。
        使用ip-hash算法时Nginx会确保来自同一客户端的请求都分发到同一服务器。
        要使用ip-hash算法时只需要在定义服务器组时加上“ip-hash ”指令
    ```
    upstream app1 {
        ip_hash;
        server 10.10.10.1;
        server 10.10.10.2;
    }
    ```


    weighted
        weighted算法也就是权重算法，会根据每个服务的权重来分发请求，权重大的请求相对会多分发一点，权重小的会少分发一点。
        这通常应用于多个服务器的性能不一致时。需要使用权重算法时只需要在定义服务器组时在服务器后面指定参数weight
    ```
    upstream app1 {
        server 10.10.10.1 weight=3;
        server 10.10.10.2;
    }
    ```

    url_hash	按照访问的URL的hash结果来分配请求，使一个URL始终定向到同一个后端服务器

    hash关键数值	hash自定义的key



Nginx是如何处理一个请求

    首先，nginx在启动时，会解析配置文件，得到需要监听的端口与ip地址，然后在nginx的master进程里面
    先初始化好这个监控的socket，再进行listen
    然后再fork出多个子进程出来, 子进程会竞争accept新的连接。
    此时，客户端就可以向nginx发起连接了。
    当客户端与nginx进行三次握手，与nginx建立好一个连接后，此时，某一个子进程会accept成功，然后创建nginx对连接的封装，即ngx_connection_t结构体接着，
    根据事件调用相应的事件处理模块，如http模块与客户端进行数据的交换，最后，nginx或客户端来主动关掉连接，到此，一个连接就寿终正寝了
















